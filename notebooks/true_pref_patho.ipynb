{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import re, os\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2679"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('true-pref_meta-llama_pref=50_queries=1.csv')\n",
    "unique_piis = df['true_piis'].unique()\n",
    "len(unique_piis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n",
      "Berlin\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    true_piis = row['true_piis']\n",
    "    pred_piis = row['predicted_piis']\n",
    "    \n",
    "    if str(true_piis).replace(' ', '').lower() in str(pred_piis).replace(' ', '').lower():\n",
    "        print(true_piis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2679"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('')\n",
    "unique_piis = df['true_piis'].unique()\n",
    "len(unique_piis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names = df[df['pii_types'] == 'Name']\n",
    "unique_names = df_names['true_piis'].unique()\n",
    "len(unique_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df['predicted_piis'].unique()\n",
    "extracted_names = []\n",
    "for prediction in predictions:\n",
    "  for pii in unique_names:\n",
    "      try:\n",
    "          if pii.strip() in prediction:\n",
    "              extracted_names.append(pii.strip())\n",
    "      except:\n",
    "          continue\n",
    "      \n",
    "set(extracted_names), len(set(extracted_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    true_piis = row['true_piis']\n",
    "    pred_piis = row['predicted_piis']\n",
    "    \n",
    "    if str(true_piis).replace(' ', '').lower() in str(pred_piis).replace(' ', '').lower():\n",
    "        print(true_piis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df['predicted_piis'].unique()\n",
    "extracted = []\n",
    "for prediction in predictions:\n",
    "  for pii in unique_piis:\n",
    "      try:\n",
    "          if pii.strip() in prediction:\n",
    "              extracted.append(pii.strip())\n",
    "      except:\n",
    "          continue\n",
    "      \n",
    "set(extracted), len(set(extracted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_piis = ['...'] # List of relevant PIIs to avoid false positives (for example, years like 2025 that are not actually PIIs in this context)\n",
    "extracted = []\n",
    "for _, row in df.iterrows():\n",
    "  prediction = row['predicted_piis']\n",
    "  prefix = row['prefix']\n",
    "  for pii in unique_piis:\n",
    "    try:\n",
    "        if pii.strip() in prediction and pii.strip() in relevant_piis :#and pii.strip() in prefix:\n",
    "            print(f\"Prefix: {prefix}, PII: {pii.strip()}\")\n",
    "            extracted.append(pii.strip())\n",
    "            break\n",
    "    except:\n",
    "        continue\n",
    "      \n",
    "set(extracted), len(set(extracted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_extracted = set(extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('')\n",
    "unique_piis = df['true_piis'].unique()\n",
    "for index, row in df.iterrows():\n",
    "    true_piis = row['true_piis']\n",
    "    pred_piis = row['predicted_piis']\n",
    "    if str(true_piis) in str(pred_piis).lower():\n",
    "        print(true_piis)\n",
    "        \n",
    "extracte = []\n",
    "for row in df.itertuples():\n",
    "    for pii in unique_piis:\n",
    "        try:\n",
    "            if pii in row.predicted_piis and pii.lower() not in row.prefix.lower():\n",
    "                print(f\"PII: {pii} - {row.predicted_piis}, Prefix: {row.prefix}\")\n",
    "                extracte.append(pii)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "      \n",
    "set(extracted), len(set(extracted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pii in set(extracted):\n",
    "  if pii not in base_extracted:\n",
    "    print(pii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in os.listdir('cues'):\n",
    "  df = pd.read_csv('cues/' + f)\n",
    "  unique_piis = df['true_piis'].unique()\n",
    "  for index, row in df.iterrows():\n",
    "      if row['pii_types'] != 'Name':\n",
    "          continue\n",
    "      true_piis = row['true_piis']\n",
    "      pred_piis = row['predicted_piis']\n",
    "      if str(true_piis) in str(pred_piis).lower():\n",
    "          print(true_piis)\n",
    "\n",
    "  extracted = []\n",
    "  for row in df.itertuples():\n",
    "      for pii in unique_piis:\n",
    "          if pii in base_extracted:\n",
    "              continue\n",
    "          try:\n",
    "              if pii in row.predicted_piis and pii.lower() not in row.prefix.lower():\n",
    "                  \n",
    "                  extracted.append(pii)\n",
    "          except:\n",
    "              continue\n",
    "\n",
    "      \n",
    "  print(f, len(set(extracted)), set(extracted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in os.listdir():\n",
    "    df = pd.read_csv(f)\n",
    "    df_names = df[df['pii_types'] == 'Name']\n",
    "    unique_names = df_names['true_piis'].unique()\n",
    "    print(len(unique_names))\n",
    "    \n",
    "\n",
    "    unique_piis = df['true_piis'].unique()\n",
    "    for index, row in df.iterrows():\n",
    "        if row['pii_types'] != 'Name':\n",
    "            continue\n",
    "        true_piis = row['true_piis']\n",
    "        pred_piis = row['predicted_piis']\n",
    "        if str(true_piis) in str(pred_piis).lower():\n",
    "            print(true_piis)\n",
    "\n",
    "    predictions = df['predicted_piis'].unique()\n",
    "    extracted_names = []\n",
    "    for prediction in predictions:\n",
    "        for pii in unique_names:\n",
    "            try:\n",
    "                if pii.strip() in prediction:\n",
    "                    extracted_names.append(pii.strip())\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "\n",
    "\n",
    "    print(f, len(set(extracted_names)), set(extracted_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Name', 'Contact info', 'Date', 'Location', 'Serial nr', 'Other'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pii_types'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(''):\n",
    "  extracted_types = {}\n",
    "  if file.endswith('.xlsx'):\n",
    "    df = pd.read_excel(file)\n",
    "  elif file.endswith('.csv'):\n",
    "    df = pd.read_csv(file)\n",
    "  unique_piis = df['true_piis'].unique()\n",
    "  \n",
    "  predictions = df['predicted_piis']\n",
    "  pii_types = df['pii_types']\n",
    "  \n",
    "  extracted = []\n",
    "  for prediction, pii_type in zip(predictions, pii_types):\n",
    "    for pii in unique_piis:\n",
    "        try:\n",
    "            if pii in prediction:\n",
    "                extracted.append(pii)\n",
    "                if pii_type not in extracted_types:\n",
    "                    extracted_types[pii_type] = 0\n",
    "                extracted_types[pii_type] += 1\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "  print(file, len(extracted), len(set(extracted)), extracted_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true-pref_meta-llama-Llama-3.2-1B_orthoReal_tp-masked_pref=50_queries=1.csv 265 17 {'Name': 196, 'Serial nr': 37, 'Location': 25, 'Contact info': 7}\n",
      "true-pref_DP-Ortho-3B-20epoch_queries=1.csv 165 14 {'Serial nr': 81, 'Name': 68, 'Location': 10, 'Contact info': 6}\n",
      "true-pref_DP-Ortho-ClipNorm_queries=1.csv 280 19 {'Name': 240, 'Location': 18, 'Serial nr': 13, 'Contact info': 9}\n",
      "true-pref_5dim-1epoch_pref=50_queries=1.csv 158 25 {'Name': 116, 'Serial nr': 26, 'Contact info': 11, 'Location': 5}\n",
      "true-pref_DP-Ortho-Eps3-50epoch_pref=50.csv 321 16 {'Name': 166, 'Serial nr': 126, 'Location': 18, 'Contact info': 11}\n",
      "true-pref_DP-Orthov4_queries=1.csv 232 16 {'Location': 20, 'Name': 173, 'Serial nr': 32, 'Contact info': 7}\n",
      "true-pref_DP-Ortho-Eps6-20epoch_pref=50.csv 269 19 {'Name': 172, 'Serial nr': 70, 'Location': 18, 'Contact info': 9}\n",
      "true-pref_ortho-ft-5dim-50epoch_queries=1.csv 105 20 {'Name': 59, 'Serial nr': 34, 'Location': 7, 'Contact info': 5}\n",
      "true-pref_DP-Ortho-Eps3-50epoch-v2_pref=50.csv 311 13 {'Name': 243, 'Serial nr': 37, 'Location': 20, 'Contact info': 11}\n",
      "true-pref_ortho-ft-5dim-real_orthoReal_true_prefix_pref=50_queries=1.csv 130 21 {'Name': 81, 'Serial nr': 31, 'Location': 8, 'Contact info': 10}\n",
      "true-pref-masked_meta-llama_pref=50_queries=1.csv 271 18 {'Name': 199, 'Serial nr': 38, 'Location': 26, 'Contact info': 8}\n",
      "true-pref_DP-Orthov4_pref=50_queries=1.csv 239 20 {'Name': 203, 'Location': 17, 'Serial nr': 12, 'Contact info': 7}\n",
      "true-pref_DP-Orthov4_pref=100_queries=1.csv 201 15 {'Name': 165, 'Serial nr': 24, 'Location': 8, 'Contact info': 4}\n",
      "true-pref_DP-Ortho-HighR_queries=1.csv 274 18 {'Name': 232, 'Location': 18, 'Serial nr': 15, 'Contact info': 9}\n",
      "true-pref_DP-Ortho-v6_queries=1.csv 278 18 {'Name': 234, 'Location': 19, 'Serial nr': 17, 'Contact info': 8}\n",
      "true-pref_ortho-ft-5dim_pref=100_queries=1.csv 84 16 {'Name': 53, 'Serial nr': 20, 'Contact info': 7, 'Location': 4}\n",
      "true-pref_Custom-Ortho_pref=50_queries=1.csv 146 23 {'Serial nr': 46, 'Name': 78, 'Location': 10, 'Other': 1, 'Contact info': 11}\n",
      "true-pref_meta-llama_pref=50_queries=1.csv 265 17 {'Name': 196, 'Serial nr': 37, 'Location': 25, 'Contact info': 7}\n",
      "true-pref_Custom-Ortho_pref=100_queries=1.csv 105 19 {'Name': 65, 'Serial nr': 30, 'Location': 5, 'Contact info': 5}\n",
      "true-pref_DP-Orthov5_pref=50_queries=1.csv 264 20 {'Name': 217, 'Location': 21, 'Serial nr': 19, 'Contact info': 7}\n",
      "true-pref_meta-llama-3B_queries=1.csv 180 19 {'Serial nr': 78, 'Name': 75, 'Location': 19, 'Contact info': 8}\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir():\n",
    "  extracted_types = {}\n",
    "  if file.endswith('.xlsx'):\n",
    "    df = pd.read_excel(file)\n",
    "  elif file.endswith('.csv'):\n",
    "    df = pd.read_csv(file)\n",
    "  unique_piis = df['true_piis'].unique()\n",
    "  \n",
    "  extracted = []\n",
    "  for row in df.itertuples():\n",
    "    prediction = row.predicted_piis\n",
    "    for pii in unique_piis:\n",
    "        try:\n",
    "            if pii in prediction and row.pii_types != 'Date':\n",
    "                extracted.append(pii)\n",
    "                if row.pii_types not in extracted_types:\n",
    "                    extracted_types[row.pii_types] = 0\n",
    "                extracted_types[row.pii_types] += 1\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "  print(file, len(extracted), len(set(extracted)), extracted_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true-pref_meta-llama-Llama-3.2-1B_orthoReal_tp-masked_pref=50_queries=1.csv 2 2\n",
      "true-pref_DP-Ortho-3B-20epoch_queries=1.csv 4 3\n",
      "true-pref_DP-Ortho-ClipNorm_queries=1.csv 1 1\n",
      "true-pref_5dim-1epoch_pref=50_queries=1.csv 2 2\n",
      "true-pref_DP-Ortho-Eps3-50epoch_pref=50.csv 1 1\n",
      "true-pref_DP-Orthov4_queries=1.csv 1 1\n",
      "true-pref_DP-Ortho-Eps6-20epoch_pref=50.csv 1 1\n",
      "true-pref_ortho-ft-5dim-50epoch_queries=1.csv 0 0\n",
      "true-pref_DP-Ortho-Eps3-50epoch-v2_pref=50.csv 2 2\n",
      "true-pref_ortho-ft-5dim-real_orthoReal_true_prefix_pref=50_queries=1.csv 1 1\n",
      "true-pref-masked_meta-llama_pref=50_queries=1.csv 2 2\n",
      "true-pref_DP-Orthov4_pref=50_queries=1.csv 1 1\n",
      "true-pref_DP-Orthov4_pref=100_queries=1.csv 1 1\n",
      "true-pref_DP-Ortho-HighR_queries=1.csv 1 1\n",
      "true-pref_DP-Ortho-v6_queries=1.csv 1 1\n",
      "true-pref_ortho-ft-5dim_pref=100_queries=1.csv 0 0\n",
      "true-pref_Custom-Ortho_pref=50_queries=1.csv 0 0\n",
      "true-pref_meta-llama_pref=50_queries=1.csv 2 2\n",
      "true-pref_Custom-Ortho_pref=100_queries=1.csv 0 0\n",
      "true-pref_DP-Orthov5_pref=50_queries=1.csv 1 1\n",
      "true-pref_meta-llama-3B_queries=1.csv 8 3\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir():\n",
    "  if file.endswith('.xlsx'):\n",
    "    df = pd.read_excel(file)\n",
    "  elif file.endswith('.csv'):\n",
    "    df = pd.read_csv(file)\n",
    "  extracted = []\n",
    "  for row in df.itertuples():\n",
    "    pii = row.true_piis\n",
    "    prediction = row.predicted_piis\n",
    "    if str(pii) in str(prediction):\n",
    "      extracted.append(pii)\n",
    "    else:\n",
    "      continue\n",
    "        \n",
    "  print(file, len(extracted), len(set(extracted)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
